from abc import ABC, abstractmethod
from pathlib import Path
import torch
import easyocr
import pickle
import cv2
import numpy as np
from detectron2 import model_zoo
from detectron2.config import get_cfg
from detectron2.data import MetadataCatalog
from detectron2.engine import DefaultPredictor
from detectron2.utils.visualizer import Visualizer
import detectron2.projects.deeplab
from facenet_pytorch import MTCNN

DETECTRON_DEFAULT = "COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml"
PAR_DIR = Path(__file__).resolve().parent
ARTIFACTS_DIR = PAR_DIR / "artifacts"

class DetectionModel(ABC):
    """ Abstract class for a detection model 
        Any new model added should implement the abstract methods and return the output in a unified format
    """

    def __init__(self):
        pass

    ##todo: add a mechanism to pre-load weights

    @abstractmethod
    def detect(image, **params):
        """ Detect objects in an image and store the results in self.predictions 
        
        Params:
            image: An input image in numpy format
            params: kwargs that are specific to each detection model
        Returns:
            predictions: A dict that should contain the following keys:
                - pred_classes: list[int], ids of the classes detected in the image
                - pred_labels: list[str], names corresponding to the classes detected
                - pred_scores: list[float], scores representing the model certainty about the class detected
                - boxes: list[list[int]], coordiantes of the box (x1,y1,x2,y2) for each class detected
                - masks: list[list[bool]], for each class detected the mask (same shape as the image)
                        that contains True if the pixel corresponds to the class. This output is generated by
                        segmentation models
                - class_names: list[str], name of each class that can be detected by the model
                - name2int: dict, mapping from class names to ids 
                - instance_ids: list[int], id of each instance within the class
        Notes:
            - All the keys above should be present in the output. If the model doen't produce the output 
            (e.g. doesn't support segmentation), the value should be an empty list
            - Other model specific keys can be added (e.g. text for ocr)
            - For the time being, all the outputs should be JSON serializable (to take into account web deployment) 
        """
        return None

class DetectronDetector(DetectionModel):
    """ Multi-class object detection and segmentation based on the Detectron2 library
        The model used is the Panoptic Segmentation model pre-trained on the COCO dataset
    """

    def __init__(self, cfg_name=DETECTRON_DEFAULT, weights_file_name = None, threshold=0.7, device='cpu'):
        super().__init__()
        self.cfg_name = cfg_name
        self.cfg = get_cfg()
        self.cfg.MODEL.DEVICE=device
        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold
        self.cfg.merge_from_file(model_zoo.get_config_file(self.cfg_name))
        if weights_file_name is not None:
            self.cfg.MODEL.WEIGHTS = str(ARTIFACTS_DIR / weights_file_name)
        else:
            self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(self.cfg_name)
        self.dataset = self.cfg.DATASETS.TRAIN[0]
        self.class_names = MetadataCatalog.get(self.dataset).thing_classes
        self.name2int = {self.class_names[i]:i for i in range(len(self.class_names))}
        self.threshold = threshold

    def detect(self, image):
        predictions = dict()
        predictor = DefaultPredictor(self.cfg)
        pred = predictor(image) # If no objects detected, pred will contain empty Tensors
        predictions["pred_classes"] = pred["instances"].pred_classes.numpy().tolist()
        predictions["pred_labels"] = [self.class_names[i] for i in list(set(predictions["pred_classes"]))]
        predictions["scores"] = pred["instances"].scores.numpy().tolist()
        predictions["boxes"] = pred["instances"].pred_boxes.tensor.numpy().astype(int).tolist()
        if hasattr(pred["instances"], "pred_masks"):
            predictions["masks"] = pred["instances"].pred_masks.numpy().tolist()
        else:
            predictions["masks"] = []
        predictions["class_names"] = self.class_names
        predictions["name2int"] = self.name2int
        predictions["instance_ids"] = list()
        counter = {self.name2int[label]:0 for label in predictions["pred_labels"]}
        for class_id in predictions["pred_classes"]:
            predictions["instance_ids"].append(counter[class_id])
            counter[class_id]+=1
        return predictions

class FaceNETDetector(DetectionModel):
    """ Face detection model using facenet
    """

    def __init__(self, margin=0, post_process=True, keep_all=True):
        super().__init__()
        self.margin = margin
        self.post_process = post_process
        self.keep_all = keep_all
        self.class_names = ['face']

    def detect(self, image):
        ##todo: check why adding the min size param (with value=5) craches
        predictions = dict()
        image_size=image.shape[1],
        predictor = MTCNN(image_size=image_size, margin=self.margin, post_process=self.post_process,
                        keep_all=self.keep_all) 
        boxes, probs = predictor.detect(image) #If no objects detected, boxes will be None
        if boxes is None:
            boxes = np.array([])
            probs = np.array([])
        predictions["pred_classes"] = [0 for _ in range(len(probs))]
        predictions["pred_labels"] = ['face'] if len(predictions["pred_classes"]) > 0 else []
        predictions["scores"] = probs.tolist()
        predictions["boxes"] = boxes.astype(int).tolist()
        predictions["masks"] = []
        predictions["class_names"] = self.class_names
        predictions["name2int"] = {'face':0}
        predictions["instance_ids"] = list(range(len(predictions["pred_classes"])))
        return predictions


class FaceDetector(DetectionModel):
    """Face Detector that performs face detection with facenet and face segmentation
    with deeplab
    """
    def __init__(self, margin=0, post_process=True, keep_all=True, expansion=20, deeplab_model=""):
        """Initialises facenet mtcnn input params and creates the deeplab default predictor
        """
        self.margin = margin
        self.post_process = post_process
        self.keep_all = keep_all
        self.class_names = ['face']

        self.deeplab_cfg = pickle.load(open(str(ARTIFACTS_DIR/(deeplab_model+"_cfg.pkl")), "rb"))
        self.deeplab_cfg.defrost()
        self.deeplab_cfg.MODEL.WEIGHTS = str(ARTIFACTS_DIR/(deeplab_model+".pth"))
        self.deeplab = DefaultPredictor(self.deeplab_cfg)
        self.expansion  = expansion
        
    def detect(self, image):
        """Detects bounding boxes with facenet and does segmentation with deeplab
        """
        facenet = FaceNETDetector(self.margin, self.post_process, self.keep_all)
        predictions = facenet.detect(image)
        boxes = predictions["boxes"]
        refined_boxes = []
        masks = []
        
        for box in boxes:
            x1,y1,x2,y2 = box
            exp_x1 = x1 - self.expansion
            exp_y1 = y1 - self.expansion
            exp_x2 = x2 + self.expansion
            exp_y2 = y2 + self.expansion
            image_patch = image.copy()[exp_y1:exp_y2+1, exp_x1:exp_x2+1]
            sem_seg = self.deeplab(image_patch)["sem_seg"]
            sem_seg = torch.max(sem_seg, dim=0)[1].cpu().numpy()
            skin_pixels = ((sem_seg==1)*255).astype('uint8')
            skin_pixels = cv2.erode(skin_pixels, np.ones((5,5), np.uint8), iterations=1)
            mask = np.zeros_like(image)[:,:,0]
            mask[exp_y1:exp_y2+1, exp_x1:exp_x2+1] = skin_pixels
            ys, xs = mask.nonzero()
            min_y, min_x = np.min(ys), np.min(xs)
            max_y, max_x = np.max(ys), np.max(xs)
            refined_boxes += [[min_x,min_y,max_x,max_y]]
            masks += [mask]
            
        predictions["boxes"] = refined_boxes
        predictions["masks"] = masks
        
        return predictions


class OCRDetector(DetectionModel):
    """ OCR model using easy ocr
    """

    def __init__(self, reader=["ch_sim","en"], gpu=False):
        super().__init__()
        self.reader = reader
        self.gpu = gpu
        self.class_names = ['text']

    def detect(self, image):
        predictions = dict()
        reader = easyocr.Reader(self.reader, gpu=self.gpu)
        pred = reader.readtext(image) # If no objects detected, pred be an empty list
        predictions["pred_classes"] = [0 for _ in range(len(pred))]
        predictions["pred_labels"] = ['text'] if len(predictions["pred_classes"]) > 0 else []
        predictions["scores"] = [p[2] for p in pred]
        predictions["boxes"] = np.array([[*p[0][0], *p[0][2]] for p in pred]).astype(int).tolist() # sometimes the function returns float!
        predictions["masks"] = []
        predictions["name2int"] = {'text':0}
        predictions["class_names"] = self.class_names
        predictions["instance_ids"] = list(range(len(predictions["pred_classes"])))
        predictions["text"] = [p[1] for p in pred]
        return predictions
    