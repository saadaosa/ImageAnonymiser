from abc import ABC, abstractmethod
from pathlib import Path

import easyocr
import numpy as np
from detectron2 import model_zoo
from detectron2.config import get_cfg
from detectron2.data import MetadataCatalog
from detectron2.engine import DefaultPredictor
from detectron2.utils.visualizer import Visualizer
from facenet_pytorch import MTCNN

DETECTRON_DEFAULT = "COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml"
PAR_DIR = Path(__file__).resolve().parent
ARTIFACTS_DIR = PAR_DIR / "artifacts"

class DetectionModel(ABC):
    """ Abstract class for a detection model 
        Any new model added should implement the abstract methods and return the output in a unified format
    """

    def __init__(self):
        pass

    @abstractmethod
    def detect(image, **params):
        """ Detect objects in an image and store the results in self.predictions 
        
        Params:
            image: An input image in numpy format
            params: kwargs that are specific to each detection model
        Returns:
            predictions: A dict that should contain the following keys:
                - pred_classes: list[int], ids of the classes detected in the image
                - pred_labels: list[str], names corresponding to the classes detected
                - pred_scores: list[float], scores representing the model certainty about the class detected
                - boxes: list[list[int]], coordiantes of the box (x1,y1,x2,y2) for each class detected
                - masks: list[list[bool]], for each class detected the mask (same shape as the image)
                        that contains True if the pixel corresponds to the class. This output is generated by
                        segmentation models
                - class_names: list[str], name of each class that can be detected by the model
                - name2int: dict, mapping from class names to ids 
                - instance_ids: list[int], id of each instance within the class
        Notes:
            - All the keys above should be present in the output. If the model doen't produce the output 
            (e.g. doesn't support segmentation), the value should be an empty list
            - Other model specific keys can be added (e.g. text for ocr)
            - For the time being, all the outputs should be JSON serializable (to take into account web deployment) 
        """
        return None

class DetectronDetector(DetectionModel):
    """ Multi-class object detection and segmentation based on the Detectron2 library
        The model used is the Panoptic Segmentation model pre-trained on the COCO dataset
    """

    def __init__(self, cfg_name=DETECTRON_DEFAULT, weights_file_name = None, threshold=0.7, device='cpu'):
        super().__init__()
        self.cfg_name = cfg_name
        self.cfg = get_cfg()
        self.cfg.MODEL.DEVICE=device
        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold
        self.cfg.merge_from_file(model_zoo.get_config_file(self.cfg_name))
        if weights_file_name is not None and Path(ARTIFACTS_DIR / weights_file_name).is_file():
            self.cfg.MODEL.WEIGHTS = str(ARTIFACTS_DIR / weights_file_name)
        else:
            self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(self.cfg_name)
        self.dataset = self.cfg.DATASETS.TRAIN[0]
        self.class_names = MetadataCatalog.get(self.dataset).thing_classes
        self.name2int = {self.class_names[i]:i for i in range(len(self.class_names))}
        self.threshold = threshold

    def detect(self, image):
        predictions = dict()
        predictor = DefaultPredictor(self.cfg)
        pred = predictor(image) # If no objects detected, pred will contain empty Tensors
        predictions["pred_classes"] = pred["instances"].pred_classes.cpu().numpy().tolist()
        predictions["pred_labels"] = [self.class_names[i] for i in list(set(predictions["pred_classes"]))]
        predictions["scores"] = pred["instances"].scores.cpu().numpy().tolist()
        predictions["boxes"] = pred["instances"].pred_boxes.tensor.cpu().numpy().astype(int).tolist()
        if hasattr(pred["instances"], "pred_masks"):
            predictions["masks"] = pred["instances"].pred_masks.cpu().numpy().tolist()
        else:
            predictions["masks"] = []
        predictions["class_names"] = self.class_names
        predictions["name2int"] = self.name2int
        predictions["instance_ids"] = list()
        counter = {self.name2int[label]:0 for label in predictions["pred_labels"]}
        for class_id in predictions["pred_classes"]:
            predictions["instance_ids"].append(counter[class_id])
            counter[class_id]+=1
        return predictions

class FaceNETDetector(DetectionModel):
    """ Face detection model using facenet
    """

    def __init__(self, min_face_size=20, thresholds=[0.6,0.7,0.7], device=None):
        super().__init__()
        self.min_face_size = min_face_size
        self.thresholds = thresholds
        self.device = device
        self.class_names = ['face']

    def detect(self, image):
        predictions = dict()
        predictor = MTCNN(keep_all=True, min_face_size=self.min_face_size, thresholds=self.thresholds, 
                        device=self.device) 
        boxes, probs = predictor.detect(image) #If no objects detected, boxes will be None
        if boxes is None:
            boxes = np.array([])
            probs = np.array([])
        else:
            boxes = boxes.astype(int)
            boxes[boxes < 0] = 0
            boxes[:,0][boxes[:,0] >= image.shape[1]] = image.shape[1]-1
            boxes[:,2][boxes[:,2] >= image.shape[1]] = image.shape[1]-1
            boxes[:,1][boxes[:,1] >= image.shape[0]] = image.shape[0]-1
            boxes[:,3][boxes[:,3] >= image.shape[0]] = image.shape[0]-1
        predictions["pred_classes"] = [0 for _ in range(len(probs))]
        predictions["pred_labels"] = ['face'] if len(predictions["pred_classes"]) > 0 else []
        predictions["scores"] = probs.tolist()
        predictions["boxes"] = boxes.tolist()
        predictions["masks"] = []
        predictions["class_names"] = self.class_names
        predictions["name2int"] = {'face':0}
        predictions["instance_ids"] = list(range(len(predictions["pred_classes"])))
        return predictions

class OCRDetector(DetectionModel):
    """ OCR model using easy ocr
    """

    def __init__(self, lang_list=["en"], gpu=False):
        super().__init__()
        self.lang_list = lang_list
        self.gpu = gpu
        self.model_storage_directory = ARTIFACTS_DIR
        self.class_names = ['text']

    def detect(self, image):
        predictions = dict()
        reader = easyocr.Reader(self.lang_list, gpu=self.gpu, model_storage_directory=self.model_storage_directory)
        pred = reader.readtext(image) # If no objects detected, pred be an empty list
        predictions["pred_classes"] = [0 for _ in range(len(pred))]
        predictions["pred_labels"] = ['text'] if len(predictions["pred_classes"]) > 0 else []
        predictions["scores"] = [p[2] for p in pred]
        predictions["boxes"] = np.array([[*p[0][0], *p[0][2]] for p in pred]).astype(int).tolist() # sometimes the function returns float!
        predictions["masks"] = []
        predictions["name2int"] = {'text':0}
        predictions["class_names"] = self.class_names
        predictions["instance_ids"] = list(range(len(predictions["pred_classes"])))
        predictions["text"] = [p[1] for p in pred]
        return predictions

class DetectronSingleDetector(DetectronDetector):
    """ Single-class object detection and segmentation based on the Detectron2 library
        Uses a multi-class model but returns the predictions only for a target class
    """

    def __init__(self, cfg_name=DETECTRON_DEFAULT, weights_file_name = None, threshold=0.7, device='cpu', target_id=0):
        super().__init__(cfg_name=cfg_name, weights_file_name = weights_file_name, threshold=threshold, device=device)
        self.target_id = target_id
        self.class_names = [MetadataCatalog.get(self.dataset).thing_classes[self.target_id]]

    def detect(self, image):
        predictions = dict()
        predictor = DefaultPredictor(self.cfg)
        pred = predictor(image) # If no objects detected, pred will contain empty Tensors
        pred_classes = pred["instances"].pred_classes.cpu().numpy()
        mask = np.array([True if i == self.target_id else False for i in pred_classes]) 
        predictions["pred_classes"] = pred_classes[mask].tolist()
        predictions["pred_labels"] = [self.class_names[i] for i in list(set(predictions["pred_classes"]))]
        predictions["scores"] = pred["instances"].scores.cpu().numpy()[mask].tolist()
        predictions["boxes"] = pred["instances"].pred_boxes.tensor.cpu().numpy().astype(int)[mask].tolist()
        if hasattr(pred["instances"], "pred_masks"):
            predictions["masks"] = pred["instances"].pred_masks.cpu().numpy()[mask].tolist()
        else:
            predictions["masks"] = []
        predictions["class_names"] = self.class_names
        predictions["name2int"] = {self.class_names[0]:self.target_id}
        predictions["instance_ids"] = list(range(len(predictions["pred_classes"])))
        return predictions
    